{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\r\n",
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))\r\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num CPUs Available:  1\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "load the data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "digits_training_data = pd.read_csv('./train.csv')\r\n",
    "\r\n",
    "# X is all the features I will be training the dataset on \r\n",
    "X = digits_training_data.copy()\r\n",
    "# y is the prediction target\r\n",
    "# pop label from the X and at the same time set the target\r\n",
    "y = X.pop('label')\r\n",
    "\r\n",
    "X.head()\r\n",
    "# y.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "# use part of the data from training and validation\r\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, stratify=y, train_size=0.75)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers\r\n",
    "\r\n",
    "# input_shape is the shape of the input data\r\n",
    "model = keras.Sequential([\r\n",
    "    layers.BatchNormalization(input_shape=(784,)),\r\n",
    "    layers.Dense(16, activation='relu'),\r\n",
    "    layers.BatchNormalization(),\r\n",
    "    layers.Dropout(0.3),  \r\n",
    "    layers.Dense(16, activation='relu'),\r\n",
    "    layers.BatchNormalization(),\r\n",
    "    layers.Dropout(0.3),  \r\n",
    "    layers.Dense(16, activation='relu'),\r\n",
    "    layers.BatchNormalization(),\r\n",
    "    layers.Dropout(0.3),  \r\n",
    "    layers.Dense(1),\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# min_delta is the minimum change in the monitored quantity to qualify as an improvement, which is used for early stopping.\r\n",
    "# patience is the number of epochs with no improvement after which training will be stopped.\r\n",
    "\r\n",
    "early_stopping = keras.callbacks.EarlyStopping(\r\n",
    "    patience=20,\r\n",
    "    min_delta=0.001,\r\n",
    "    restore_best_weights=True,\r\n",
    ")\r\n",
    "\r\n",
    "# optimizer is the algorithm used to update the weights of the model.\r\n",
    "# loss is the loss function to be minimized by the model.\r\n",
    "model.compile(\r\n",
    "    optimizer='adam',\r\n",
    "    loss='mae',\r\n",
    ")\r\n",
    "\r\n",
    "# batch size is the number of samples (rows) that will be processed at a time\r\n",
    "# epochs is the number of times the entire dataset will be processed\r\n",
    "history = model.fit(\r\n",
    "    X_train, y_train,\r\n",
    "    validation_data=(X_valid, y_valid),\r\n",
    "    batch_size=256,\r\n",
    "    epochs=1000,\r\n",
    "    callbacks=[early_stopping],\r\n",
    ")\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "plt.style.use('seaborn-whitegrid')\r\n",
    "# Set Matplotlib defaults\r\n",
    "plt.rc('figure', autolayout=True)\r\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\r\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\r\n",
    "plt.rc('animation', html='html5')\r\n",
    "\r\n",
    "history_df = pd.DataFrame(history.history)\r\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot()\r\n",
    "print(\"Minimum Validation Loss: {:0.4f}\".format(history_df['val_loss'].min()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/1000\n",
      "124/124 [==============================] - 2s 8ms/step - loss: 4.1957 - val_loss: 3.7908\n",
      "Epoch 2/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 3.1933 - val_loss: 2.1886\n",
      "Epoch 3/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 2.0641 - val_loss: 1.1995\n",
      "Epoch 4/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 1.6514 - val_loss: 0.9489\n",
      "Epoch 5/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 1.5043 - val_loss: 0.9131\n",
      "Epoch 6/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 1.4130 - val_loss: 0.8709\n",
      "Epoch 7/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 1.3399 - val_loss: 0.8375\n",
      "Epoch 8/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 1.2810 - val_loss: 0.8040\n",
      "Epoch 9/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 1.2462 - val_loss: 0.7924\n",
      "Epoch 10/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 1.2016 - val_loss: 0.7653\n",
      "Epoch 11/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 1.1727 - val_loss: 0.7345\n",
      "Epoch 12/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 1.1661 - val_loss: 0.7381\n",
      "Epoch 13/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 1.1472 - val_loss: 0.7464\n",
      "Epoch 14/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 1.1266 - val_loss: 0.7068\n",
      "Epoch 15/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 1.0971 - val_loss: 0.7074\n",
      "Epoch 16/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 1.0853 - val_loss: 0.7157\n",
      "Epoch 17/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 1.0807 - val_loss: 0.6730\n",
      "Epoch 18/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 1.0600 - val_loss: 0.6836\n",
      "Epoch 19/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 1.0526 - val_loss: 0.6616\n",
      "Epoch 20/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 1.0388 - val_loss: 0.6969\n",
      "Epoch 21/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 1.0234 - val_loss: 0.6580\n",
      "Epoch 22/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 1.0194 - val_loss: 0.6463\n",
      "Epoch 23/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 1.0065 - val_loss: 0.6086\n",
      "Epoch 24/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.9958 - val_loss: 0.6061\n",
      "Epoch 25/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.9842 - val_loss: 0.6234\n",
      "Epoch 26/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.9933 - val_loss: 0.6088\n",
      "Epoch 27/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.9884 - val_loss: 0.6219\n",
      "Epoch 28/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.9699 - val_loss: 0.5877\n",
      "Epoch 29/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.9731 - val_loss: 0.5960\n",
      "Epoch 30/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.9703 - val_loss: 0.5581\n",
      "Epoch 31/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.9519 - val_loss: 0.5523\n",
      "Epoch 32/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.9444 - val_loss: 0.5592\n",
      "Epoch 33/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.9465 - val_loss: 0.5737\n",
      "Epoch 34/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.9398 - val_loss: 0.5851\n",
      "Epoch 35/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.9423 - val_loss: 0.5696\n",
      "Epoch 36/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.9281 - val_loss: 0.5765\n",
      "Epoch 37/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.9308 - val_loss: 0.5540\n",
      "Epoch 38/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.9129 - val_loss: 0.5378\n",
      "Epoch 39/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.9109 - val_loss: 0.5318\n",
      "Epoch 40/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.9153 - val_loss: 0.5459\n",
      "Epoch 41/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.9017 - val_loss: 0.5405\n",
      "Epoch 42/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.9114 - val_loss: 0.5152\n",
      "Epoch 43/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8914 - val_loss: 0.5307\n",
      "Epoch 44/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8920 - val_loss: 0.5210\n",
      "Epoch 45/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8979 - val_loss: 0.5183\n",
      "Epoch 46/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8919 - val_loss: 0.5449\n",
      "Epoch 47/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8857 - val_loss: 0.5227\n",
      "Epoch 48/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8929 - val_loss: 0.5251\n",
      "Epoch 49/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8876 - val_loss: 0.5254\n",
      "Epoch 50/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8830 - val_loss: 0.5157\n",
      "Epoch 51/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8759 - val_loss: 0.5277\n",
      "Epoch 52/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8784 - val_loss: 0.5161\n",
      "Epoch 53/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8737 - val_loss: 0.5065\n",
      "Epoch 54/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8670 - val_loss: 0.5238\n",
      "Epoch 55/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8636 - val_loss: 0.5104\n",
      "Epoch 56/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8686 - val_loss: 0.4974\n",
      "Epoch 57/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8600 - val_loss: 0.4996\n",
      "Epoch 58/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8667 - val_loss: 0.4917\n",
      "Epoch 59/1000\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.8556 - val_loss: 0.5031\n",
      "Epoch 60/1000\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.8662 - val_loss: 0.4854\n",
      "Epoch 61/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8540 - val_loss: 0.5143\n",
      "Epoch 62/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8463 - val_loss: 0.4955\n",
      "Epoch 63/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8451 - val_loss: 0.4875\n",
      "Epoch 64/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8470 - val_loss: 0.4839\n",
      "Epoch 65/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8416 - val_loss: 0.5032\n",
      "Epoch 66/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8407 - val_loss: 0.4828\n",
      "Epoch 67/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8492 - val_loss: 0.4757\n",
      "Epoch 68/1000\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.8378 - val_loss: 0.4860\n",
      "Epoch 69/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8342 - val_loss: 0.4939\n",
      "Epoch 70/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8338 - val_loss: 0.5109\n",
      "Epoch 71/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8316 - val_loss: 0.5092\n",
      "Epoch 72/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8346 - val_loss: 0.4809\n",
      "Epoch 73/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8433 - val_loss: 0.4708\n",
      "Epoch 74/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8357 - val_loss: 0.4715\n",
      "Epoch 75/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8274 - val_loss: 0.4696\n",
      "Epoch 76/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8244 - val_loss: 0.4852\n",
      "Epoch 77/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8235 - val_loss: 0.4804\n",
      "Epoch 78/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8216 - val_loss: 0.4656\n",
      "Epoch 79/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8303 - val_loss: 0.4784\n",
      "Epoch 80/1000\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.8241 - val_loss: 0.4757\n",
      "Epoch 81/1000\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.8140 - val_loss: 0.4567\n",
      "Epoch 82/1000\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 0.8319 - val_loss: 0.4532\n",
      "Epoch 83/1000\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.8139 - val_loss: 0.4605\n",
      "Epoch 84/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8110 - val_loss: 0.4868\n",
      "Epoch 85/1000\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.8197 - val_loss: 0.4802\n",
      "Epoch 86/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8202 - val_loss: 0.4803\n",
      "Epoch 87/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8096 - val_loss: 0.4580\n",
      "Epoch 88/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8197 - val_loss: 0.4643\n",
      "Epoch 89/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8103 - val_loss: 0.4567\n",
      "Epoch 90/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8162 - val_loss: 0.5152\n",
      "Epoch 91/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8162 - val_loss: 0.4734\n",
      "Epoch 92/1000\n",
      "124/124 [==============================] - 1s 8ms/step - loss: 0.8093 - val_loss: 0.4966\n",
      "Epoch 93/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8130 - val_loss: 0.4569\n",
      "Epoch 94/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8089 - val_loss: 0.4608\n",
      "Epoch 95/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8061 - val_loss: 0.4698\n",
      "Epoch 96/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8134 - val_loss: 0.4712\n",
      "Epoch 97/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8125 - val_loss: 0.4585\n",
      "Epoch 98/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8072 - val_loss: 0.4745\n",
      "Epoch 99/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.8091 - val_loss: 0.4740\n",
      "Epoch 100/1000\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.7914 - val_loss: 0.4540\n",
      "Epoch 101/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.8082 - val_loss: 0.4794\n",
      "Epoch 102/1000\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 0.7942 - val_loss: 0.4867\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18424/1398167668.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'seaborn-whitegrid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Set Matplotlib defaults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('tf': conda)"
  },
  "interpreter": {
   "hash": "f25a34d828536eaea94bc98fa02bf2fcbf5af5b65bea44899cc5ad2220dc98c9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}